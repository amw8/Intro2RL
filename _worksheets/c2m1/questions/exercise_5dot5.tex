 (\textit{Exercise 5.5 S\&B}) Consider an MDP with a single nonterminal state $s$ and a single action
that transitions back to the nonterminal state with probability $p$ and transitions to the
terminal state with probability $1-p$. Let the reward be $+1$ on all transitions, and let
 $\gamma = 1$. Suppose you observe one episode that lasts $10$ steps, with a return of $10$. What
is the (every-visit) Monte-carlo estimator of the value of the nonterminal state $s$?
%
\begin{figure}[h!]
  \center
\includegraphics[width=0.5\linewidth]{figures/c2_mc_everyvisit.pdf}
\end{figure}