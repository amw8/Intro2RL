\textbf{Challenge Question:} Recall that the mean-squared value error is 
$$\overline{\text{VE}}(\mathbf{w}) = \sum_{s \in \mathcal{S}} \mu(s) (v_\pi(s) - \hat{v}(s, \mathbf{w}))^2.$$ 
We discussed one choice for $\mu$, which is to use the state visitation under the behavior policy. Namely, as the policy is executed in the state, the weighting $\mu(s)$ is proportional to how frequently the agent is in state $s$. What are some other weightings could be used instead?