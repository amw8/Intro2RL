Recall that an optimal policy satisfies the Bellman optimality equation.
Suppose we have an optimal policy $\pi_1$ for a certain MDP, MDP1.
Show that $\pi_1$ is also optimal for an MDP where
the expected reward for any state action pair $(s,a)$ is related
to the expected reward in MDP1 by the following equation
$\mathbb{E}[R|s,a] =x\mathbb{E}_{MDP 1}[R|s,a]+y$ for some
constants $x , y \in \mathbb{R}$.
What happens when $x=0$, what is the set of optimal policies for this case?
\smallspace
